{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "72_VZTxWXwAh"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torchvision\n",
        "from torchvision import datasets\n",
        "from torchvision import transforms\n",
        "from torchvision.transforms import ToTensor\n",
        "from pathlib import Path\n",
        "import os\n",
        "from PIL import Image\n",
        "from matplotlib import pyplot as plt\n",
        "import glob"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda'"
      ],
      "metadata": {
        "id": "MtMb5NzOPi8D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "9s1_AR7k_W0J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19b00e4e-4389-44fe-9b3c-e9496a23c80b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/drive/MyDrive/AIP/Train_Test_dataset.zip"
      ],
      "metadata": {
        "id": "pBRT7Ty4dnj_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Transforming data with torchvision.transforms\n",
        "\n",
        "train_data_transforms = transforms.Compose([\n",
        "        transforms.RandomResizedCrop(64, scale=(1,1)),\n",
        "        transforms.RandomHorizontalFlip(p=0.5),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "test_data_transforms = transforms.Compose([\n",
        "        transforms.RandomResizedCrop(64, scale=(1,1)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ])"
      ],
      "metadata": {
        "id": "pAkAX7SDmkwh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision import datasets\n",
        "train_data = datasets.ImageFolder(root='/content/classification_dataset/train',\n",
        "                                  transform = train_data_transforms,\n",
        "                                  target_transform = None)\n",
        "test_data = datasets.ImageFolder(root='/content/classification_dataset/test',\n",
        "                                  transform = test_data_transforms,\n",
        "                                  target_transform = None)"
      ],
      "metadata": {
        "id": "BEXazwS9tS3F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Turn train and test datasets into DataLoader\n",
        "from torch.utils.data import DataLoader\n",
        "batch = 32\n",
        "train_dataloader = DataLoader(train_data, batch, shuffle= True)\n",
        "test_dataloader = DataLoader(test_data, batch, shuffle= True)"
      ],
      "metadata": {
        "id": "0rJbAZP_0l_O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## Creating Tiny VGG Model  \n",
        "# torch.cuda.empty_cache()\n",
        "\n",
        "class TinyVGG(nn.Module):\n",
        "  def __init__(self, input_shape, hidden_units, output_shape):\n",
        "    super().__init__()\n",
        "    self.conv_1 = nn.Sequential(\n",
        "        nn.Dropout(p=0.2),\n",
        "        nn.Conv2d(in_channels=input_shape, \n",
        "                  out_channels=hidden_units,\n",
        "                  kernel_size = 3,\n",
        "                  stride=1,\n",
        "                  padding=0),\n",
        "        nn.MaxPool2d(kernel_size=2,\n",
        "                     stride=2),\n",
        "       \n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=3,\n",
        "                     stride=3)\n",
        "    )\n",
        "    self.classifier = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Dropout(p=0.5),\n",
        "        nn.Linear(in_features=hidden_units*10*10,\n",
        "                  out_features=output_shape)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    x= self.conv_1(x)\n",
        "    # print(x.shape)\n",
        "\n",
        "    x= self.classifier(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "U2Kn708U4hQ3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = TinyVGG(input_shape=3, hidden_units=5, output_shape=6).to('cuda')\n",
        "model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gV4nNZ3M8YjG",
        "outputId": "183d7093-d939-4727-d62b-3efc8d4dcddb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TinyVGG(\n",
              "  (conv_1): Sequential(\n",
              "    (0): Dropout(p=0.2, inplace=False)\n",
              "    (1): Conv2d(3, 5, kernel_size=(3, 3), stride=(1, 1))\n",
              "    (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
              "    (3): ReLU()\n",
              "    (4): MaxPool2d(kernel_size=3, stride=3, padding=0, dilation=1, ceil_mode=False)\n",
              "  )\n",
              "  (classifier): Sequential(\n",
              "    (0): Flatten(start_dim=1, end_dim=-1)\n",
              "    (1): Dropout(p=0.5, inplace=False)\n",
              "    (2): Linear(in_features=500, out_features=6, bias=True)\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "### MODEL TRAINING ###\n",
        "epochs = 1000\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = torch.optim.SGD(params=model.parameters(), lr=0.001)\n",
        "\n",
        "model.train()\n",
        "\n",
        "train_loss, train_acc = 0,0\n",
        "\n",
        "for epoch in range(epochs):\n",
        "  for batch, (X,y) in enumerate(train_dataloader):\n",
        "    Input, label = X.to('cuda'), y.to('cuda')\n",
        "\n",
        "    y_pred = model(Input)\n",
        "    loss = loss_fn(y_pred, label)\n",
        "\n",
        "\n",
        "    train_loss+=loss.item()\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    #### Calc Accuracy\n",
        "\n",
        "    y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)\n",
        "    \n",
        "    train_acc+= (y_pred_class==label).sum().item()/len(y_pred)\n",
        "  train_loss = train_loss/len(train_dataloader)\n",
        "  train_acc = train_acc / len(train_dataloader)\n",
        "    \n",
        "  ### MODEL TESTING AND ACC CALCULATION ####\n",
        "\n",
        "  model.eval()\n",
        "  test_loss, test_acc = 0, 0\n",
        "  with torch.inference_mode():\n",
        "    for batch , (X,y) in enumerate(test_dataloader):\n",
        "      Input, label = X.to('cuda'), y.to('cuda')\n",
        "\n",
        "      test_pred_logits = model(Input)\n",
        "\n",
        "      loss = loss_fn(test_pred_logits, label)\n",
        "      test_loss += loss.item()\n",
        "\n",
        "      test_pred_labels = test_pred_logits.argmax(dim=1)\n",
        "      test_acc+= ((test_pred_labels==label).sum().item()/len(test_pred_labels))\n",
        "\n",
        "    test_loss = test_loss/ len(test_dataloader)\n",
        "    test_acc = test_acc / len(test_dataloader)\n",
        "    # if epoch%5 == 0:\n",
        "    print(f'epoch: {epoch} Train Loss: {train_loss:.5f} Train Acc: {train_acc:.5f} Test Loss: {test_loss:.5f} Test Accuracy: {test_acc:.5f}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4pn7AYNCEfZH",
        "outputId": "57aec3af-bcfe-4a2d-b2c6-fb07f125425f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0 Train Loss: 1.89829 Train Acc: 0.21765 Test Loss: 1.76167 Test Accuracy: 0.20312\n",
            "epoch: 1 Train Loss: 1.87232 Train Acc: 0.25692 Test Loss: 1.75960 Test Accuracy: 0.21094\n",
            "epoch: 2 Train Loss: 1.86272 Train Acc: 0.26916 Test Loss: 1.74986 Test Accuracy: 0.26302\n",
            "epoch: 3 Train Loss: 1.85762 Train Acc: 0.28274 Test Loss: 1.74945 Test Accuracy: 0.28125\n",
            "epoch: 4 Train Loss: 1.85295 Train Acc: 0.28134 Test Loss: 1.74695 Test Accuracy: 0.25521\n",
            "epoch: 5 Train Loss: 1.85574 Train Acc: 0.27905 Test Loss: 1.74347 Test Accuracy: 0.29167\n",
            "epoch: 6 Train Loss: 1.84342 Train Acc: 0.30244 Test Loss: 1.73089 Test Accuracy: 0.29167\n",
            "epoch: 7 Train Loss: 1.83255 Train Acc: 0.30456 Test Loss: 1.72748 Test Accuracy: 0.28385\n",
            "epoch: 8 Train Loss: 1.83052 Train Acc: 0.30652 Test Loss: 1.72363 Test Accuracy: 0.30729\n",
            "epoch: 9 Train Loss: 1.82783 Train Acc: 0.31215 Test Loss: 1.71993 Test Accuracy: 0.30990\n",
            "epoch: 10 Train Loss: 1.82541 Train Acc: 0.32167 Test Loss: 1.72155 Test Accuracy: 0.30469\n",
            "epoch: 11 Train Loss: 1.82492 Train Acc: 0.31782 Test Loss: 1.71099 Test Accuracy: 0.33073\n",
            "epoch: 12 Train Loss: 1.81700 Train Acc: 0.33156 Test Loss: 1.71119 Test Accuracy: 0.32552\n",
            "epoch: 13 Train Loss: 1.81427 Train Acc: 0.35075 Test Loss: 1.70387 Test Accuracy: 0.32031\n",
            "epoch: 14 Train Loss: 1.80743 Train Acc: 0.34049 Test Loss: 1.69974 Test Accuracy: 0.31771\n",
            "epoch: 15 Train Loss: 1.79953 Train Acc: 0.34834 Test Loss: 1.69288 Test Accuracy: 0.32031\n",
            "epoch: 16 Train Loss: 1.81453 Train Acc: 0.32270 Test Loss: 1.69108 Test Accuracy: 0.33073\n",
            "epoch: 17 Train Loss: 1.79476 Train Acc: 0.34692 Test Loss: 1.68967 Test Accuracy: 0.33073\n",
            "epoch: 18 Train Loss: 1.79071 Train Acc: 0.34063 Test Loss: 1.67813 Test Accuracy: 0.35417\n",
            "epoch: 19 Train Loss: 1.79547 Train Acc: 0.33327 Test Loss: 1.68119 Test Accuracy: 0.36198\n",
            "epoch: 20 Train Loss: 1.78036 Train Acc: 0.35821 Test Loss: 1.67186 Test Accuracy: 0.37240\n",
            "epoch: 21 Train Loss: 1.77767 Train Acc: 0.36335 Test Loss: 1.67251 Test Accuracy: 0.36458\n",
            "epoch: 22 Train Loss: 1.77225 Train Acc: 0.34931 Test Loss: 1.66803 Test Accuracy: 0.35677\n",
            "epoch: 23 Train Loss: 1.77663 Train Acc: 0.35364 Test Loss: 1.65811 Test Accuracy: 0.35938\n",
            "epoch: 24 Train Loss: 1.77274 Train Acc: 0.35830 Test Loss: 1.65630 Test Accuracy: 0.36719\n",
            "epoch: 25 Train Loss: 1.77032 Train Acc: 0.35527 Test Loss: 1.65403 Test Accuracy: 0.36198\n",
            "epoch: 26 Train Loss: 1.76265 Train Acc: 0.35435 Test Loss: 1.64533 Test Accuracy: 0.37240\n",
            "epoch: 27 Train Loss: 1.74870 Train Acc: 0.34805 Test Loss: 1.65070 Test Accuracy: 0.34896\n",
            "epoch: 28 Train Loss: 1.75244 Train Acc: 0.34878 Test Loss: 1.64024 Test Accuracy: 0.36458\n",
            "epoch: 29 Train Loss: 1.75767 Train Acc: 0.35618 Test Loss: 1.64058 Test Accuracy: 0.35938\n",
            "epoch: 30 Train Loss: 1.74698 Train Acc: 0.34669 Test Loss: 1.63615 Test Accuracy: 0.35677\n",
            "epoch: 31 Train Loss: 1.75482 Train Acc: 0.35275 Test Loss: 1.62689 Test Accuracy: 0.36458\n",
            "epoch: 32 Train Loss: 1.74764 Train Acc: 0.36119 Test Loss: 1.61681 Test Accuracy: 0.37760\n",
            "epoch: 33 Train Loss: 1.73994 Train Acc: 0.35360 Test Loss: 1.61768 Test Accuracy: 0.36979\n",
            "epoch: 34 Train Loss: 1.73555 Train Acc: 0.35315 Test Loss: 1.61735 Test Accuracy: 0.37240\n",
            "epoch: 35 Train Loss: 1.72896 Train Acc: 0.35938 Test Loss: 1.61406 Test Accuracy: 0.36458\n",
            "epoch: 36 Train Loss: 1.71568 Train Acc: 0.39136 Test Loss: 1.60807 Test Accuracy: 0.37500\n",
            "epoch: 37 Train Loss: 1.72265 Train Acc: 0.37523 Test Loss: 1.60639 Test Accuracy: 0.38281\n",
            "epoch: 38 Train Loss: 1.71990 Train Acc: 0.36288 Test Loss: 1.60660 Test Accuracy: 0.38281\n",
            "epoch: 39 Train Loss: 1.71295 Train Acc: 0.39083 Test Loss: 1.59857 Test Accuracy: 0.38281\n",
            "epoch: 40 Train Loss: 1.70890 Train Acc: 0.37373 Test Loss: 1.59516 Test Accuracy: 0.38802\n",
            "epoch: 41 Train Loss: 1.71192 Train Acc: 0.37897 Test Loss: 1.59382 Test Accuracy: 0.38281\n",
            "epoch: 42 Train Loss: 1.70175 Train Acc: 0.38590 Test Loss: 1.58717 Test Accuracy: 0.38802\n",
            "epoch: 43 Train Loss: 1.70007 Train Acc: 0.39329 Test Loss: 1.58149 Test Accuracy: 0.41406\n",
            "epoch: 44 Train Loss: 1.69535 Train Acc: 0.38122 Test Loss: 1.58113 Test Accuracy: 0.39323\n",
            "epoch: 45 Train Loss: 1.68937 Train Acc: 0.39632 Test Loss: 1.57340 Test Accuracy: 0.40104\n",
            "epoch: 46 Train Loss: 1.69480 Train Acc: 0.39464 Test Loss: 1.57089 Test Accuracy: 0.40104\n",
            "epoch: 47 Train Loss: 1.69611 Train Acc: 0.38902 Test Loss: 1.56513 Test Accuracy: 0.40885\n",
            "epoch: 48 Train Loss: 1.68306 Train Acc: 0.38244 Test Loss: 1.56958 Test Accuracy: 0.41146\n",
            "epoch: 49 Train Loss: 1.68583 Train Acc: 0.40264 Test Loss: 1.56474 Test Accuracy: 0.40885\n",
            "epoch: 50 Train Loss: 1.69190 Train Acc: 0.40898 Test Loss: 1.55749 Test Accuracy: 0.42188\n",
            "epoch: 51 Train Loss: 1.66902 Train Acc: 0.41303 Test Loss: 1.55662 Test Accuracy: 0.44531\n",
            "epoch: 52 Train Loss: 1.67128 Train Acc: 0.40775 Test Loss: 1.55313 Test Accuracy: 0.46094\n",
            "epoch: 53 Train Loss: 1.66771 Train Acc: 0.40560 Test Loss: 1.55370 Test Accuracy: 0.45573\n",
            "epoch: 54 Train Loss: 1.66690 Train Acc: 0.39923 Test Loss: 1.54707 Test Accuracy: 0.45052\n",
            "epoch: 55 Train Loss: 1.65881 Train Acc: 0.40510 Test Loss: 1.54319 Test Accuracy: 0.46094\n",
            "epoch: 56 Train Loss: 1.66131 Train Acc: 0.39258 Test Loss: 1.54428 Test Accuracy: 0.47917\n",
            "epoch: 57 Train Loss: 1.65126 Train Acc: 0.42530 Test Loss: 1.53121 Test Accuracy: 0.48958\n",
            "epoch: 58 Train Loss: 1.65673 Train Acc: 0.41252 Test Loss: 1.54321 Test Accuracy: 0.48177\n",
            "epoch: 59 Train Loss: 1.65229 Train Acc: 0.41250 Test Loss: 1.53414 Test Accuracy: 0.48177\n",
            "epoch: 60 Train Loss: 1.64436 Train Acc: 0.41985 Test Loss: 1.53142 Test Accuracy: 0.49479\n",
            "epoch: 61 Train Loss: 1.64830 Train Acc: 0.42359 Test Loss: 1.51670 Test Accuracy: 0.49479\n",
            "epoch: 62 Train Loss: 1.63721 Train Acc: 0.44330 Test Loss: 1.52551 Test Accuracy: 0.47135\n",
            "epoch: 63 Train Loss: 1.63563 Train Acc: 0.42828 Test Loss: 1.51767 Test Accuracy: 0.48698\n",
            "epoch: 64 Train Loss: 1.63448 Train Acc: 0.43843 Test Loss: 1.51013 Test Accuracy: 0.50000\n",
            "epoch: 65 Train Loss: 1.62867 Train Acc: 0.43682 Test Loss: 1.50385 Test Accuracy: 0.50000\n",
            "epoch: 66 Train Loss: 1.62149 Train Acc: 0.45511 Test Loss: 1.51132 Test Accuracy: 0.49740\n",
            "epoch: 67 Train Loss: 1.61558 Train Acc: 0.45104 Test Loss: 1.50805 Test Accuracy: 0.48958\n",
            "epoch: 68 Train Loss: 1.61646 Train Acc: 0.44786 Test Loss: 1.50800 Test Accuracy: 0.48958\n",
            "epoch: 69 Train Loss: 1.61104 Train Acc: 0.43186 Test Loss: 1.49373 Test Accuracy: 0.51302\n",
            "epoch: 70 Train Loss: 1.62401 Train Acc: 0.44195 Test Loss: 1.49416 Test Accuracy: 0.48958\n",
            "epoch: 71 Train Loss: 1.61361 Train Acc: 0.42600 Test Loss: 1.49296 Test Accuracy: 0.50781\n",
            "epoch: 72 Train Loss: 1.59451 Train Acc: 0.44675 Test Loss: 1.48744 Test Accuracy: 0.51042\n",
            "epoch: 73 Train Loss: 1.61121 Train Acc: 0.45385 Test Loss: 1.48027 Test Accuracy: 0.51823\n",
            "epoch: 74 Train Loss: 1.60564 Train Acc: 0.45611 Test Loss: 1.48134 Test Accuracy: 0.50521\n",
            "epoch: 75 Train Loss: 1.59579 Train Acc: 0.44337 Test Loss: 1.48246 Test Accuracy: 0.50781\n",
            "epoch: 76 Train Loss: 1.58657 Train Acc: 0.45770 Test Loss: 1.48479 Test Accuracy: 0.51302\n",
            "epoch: 77 Train Loss: 1.59681 Train Acc: 0.44935 Test Loss: 1.47206 Test Accuracy: 0.50781\n",
            "epoch: 78 Train Loss: 1.58677 Train Acc: 0.43599 Test Loss: 1.48010 Test Accuracy: 0.48438\n",
            "epoch: 79 Train Loss: 1.58661 Train Acc: 0.45285 Test Loss: 1.47451 Test Accuracy: 0.50000\n",
            "epoch: 80 Train Loss: 1.58341 Train Acc: 0.44759 Test Loss: 1.47469 Test Accuracy: 0.51562\n",
            "epoch: 81 Train Loss: 1.58008 Train Acc: 0.46199 Test Loss: 1.45864 Test Accuracy: 0.52865\n",
            "epoch: 82 Train Loss: 1.58057 Train Acc: 0.45843 Test Loss: 1.47082 Test Accuracy: 0.51302\n",
            "epoch: 83 Train Loss: 1.57155 Train Acc: 0.46704 Test Loss: 1.46668 Test Accuracy: 0.53125\n",
            "epoch: 84 Train Loss: 1.55976 Train Acc: 0.47416 Test Loss: 1.46048 Test Accuracy: 0.49740\n",
            "epoch: 85 Train Loss: 1.57270 Train Acc: 0.46907 Test Loss: 1.46829 Test Accuracy: 0.50781\n",
            "epoch: 86 Train Loss: 1.55821 Train Acc: 0.46325 Test Loss: 1.46197 Test Accuracy: 0.51823\n",
            "epoch: 87 Train Loss: 1.56083 Train Acc: 0.46659 Test Loss: 1.44603 Test Accuracy: 0.53646\n",
            "epoch: 88 Train Loss: 1.55178 Train Acc: 0.47892 Test Loss: 1.44530 Test Accuracy: 0.53646\n",
            "epoch: 89 Train Loss: 1.56204 Train Acc: 0.47082 Test Loss: 1.44719 Test Accuracy: 0.52344\n",
            "epoch: 90 Train Loss: 1.55890 Train Acc: 0.47439 Test Loss: 1.45773 Test Accuracy: 0.51562\n",
            "epoch: 91 Train Loss: 1.54751 Train Acc: 0.47276 Test Loss: 1.43893 Test Accuracy: 0.52865\n",
            "epoch: 92 Train Loss: 1.54382 Train Acc: 0.47707 Test Loss: 1.44486 Test Accuracy: 0.53646\n",
            "epoch: 93 Train Loss: 1.52820 Train Acc: 0.49387 Test Loss: 1.43849 Test Accuracy: 0.53906\n",
            "epoch: 94 Train Loss: 1.53791 Train Acc: 0.49412 Test Loss: 1.43001 Test Accuracy: 0.55469\n",
            "epoch: 95 Train Loss: 1.53198 Train Acc: 0.47796 Test Loss: 1.43789 Test Accuracy: 0.53385\n",
            "epoch: 96 Train Loss: 1.53532 Train Acc: 0.48584 Test Loss: 1.44858 Test Accuracy: 0.53125\n",
            "epoch: 97 Train Loss: 1.52279 Train Acc: 0.48703 Test Loss: 1.42481 Test Accuracy: 0.54167\n",
            "epoch: 98 Train Loss: 1.51300 Train Acc: 0.48710 Test Loss: 1.42534 Test Accuracy: 0.54427\n",
            "epoch: 99 Train Loss: 1.51600 Train Acc: 0.50402 Test Loss: 1.43200 Test Accuracy: 0.54688\n",
            "epoch: 100 Train Loss: 1.52463 Train Acc: 0.49693 Test Loss: 1.42309 Test Accuracy: 0.53906\n",
            "epoch: 101 Train Loss: 1.51103 Train Acc: 0.49578 Test Loss: 1.42831 Test Accuracy: 0.54427\n",
            "epoch: 102 Train Loss: 1.50072 Train Acc: 0.50306 Test Loss: 1.41609 Test Accuracy: 0.54688\n",
            "epoch: 103 Train Loss: 1.49526 Train Acc: 0.52040 Test Loss: 1.43102 Test Accuracy: 0.52344\n",
            "epoch: 104 Train Loss: 1.50640 Train Acc: 0.49569 Test Loss: 1.42521 Test Accuracy: 0.53385\n",
            "epoch: 105 Train Loss: 1.51382 Train Acc: 0.48467 Test Loss: 1.41838 Test Accuracy: 0.53646\n",
            "epoch: 106 Train Loss: 1.50586 Train Acc: 0.49211 Test Loss: 1.40858 Test Accuracy: 0.55208\n",
            "epoch: 107 Train Loss: 1.47937 Train Acc: 0.53814 Test Loss: 1.41094 Test Accuracy: 0.51823\n",
            "epoch: 108 Train Loss: 1.49052 Train Acc: 0.49893 Test Loss: 1.39536 Test Accuracy: 0.55469\n",
            "epoch: 109 Train Loss: 1.49672 Train Acc: 0.49589 Test Loss: 1.41151 Test Accuracy: 0.52604\n",
            "epoch: 110 Train Loss: 1.48759 Train Acc: 0.50343 Test Loss: 1.39898 Test Accuracy: 0.52865\n",
            "epoch: 111 Train Loss: 1.48616 Train Acc: 0.50241 Test Loss: 1.39746 Test Accuracy: 0.53906\n",
            "epoch: 112 Train Loss: 1.49323 Train Acc: 0.50161 Test Loss: 1.40048 Test Accuracy: 0.53125\n",
            "epoch: 113 Train Loss: 1.48918 Train Acc: 0.50009 Test Loss: 1.39916 Test Accuracy: 0.53906\n",
            "epoch: 114 Train Loss: 1.47993 Train Acc: 0.50993 Test Loss: 1.40042 Test Accuracy: 0.55469\n",
            "epoch: 115 Train Loss: 1.47117 Train Acc: 0.53110 Test Loss: 1.39221 Test Accuracy: 0.54688\n",
            "epoch: 116 Train Loss: 1.46746 Train Acc: 0.50955 Test Loss: 1.39802 Test Accuracy: 0.54948\n",
            "epoch: 117 Train Loss: 1.47505 Train Acc: 0.50387 Test Loss: 1.39538 Test Accuracy: 0.54688\n",
            "epoch: 118 Train Loss: 1.46591 Train Acc: 0.50464 Test Loss: 1.39269 Test Accuracy: 0.53906\n",
            "epoch: 119 Train Loss: 1.45901 Train Acc: 0.52123 Test Loss: 1.39109 Test Accuracy: 0.54688\n",
            "epoch: 120 Train Loss: 1.45897 Train Acc: 0.51448 Test Loss: 1.39628 Test Accuracy: 0.55729\n",
            "epoch: 121 Train Loss: 1.45000 Train Acc: 0.51703 Test Loss: 1.39451 Test Accuracy: 0.55208\n",
            "epoch: 122 Train Loss: 1.44588 Train Acc: 0.53446 Test Loss: 1.38828 Test Accuracy: 0.52604\n",
            "epoch: 123 Train Loss: 1.44229 Train Acc: 0.53034 Test Loss: 1.38108 Test Accuracy: 0.55990\n",
            "epoch: 124 Train Loss: 1.45155 Train Acc: 0.51906 Test Loss: 1.37164 Test Accuracy: 0.56510\n",
            "epoch: 125 Train Loss: 1.43712 Train Acc: 0.53384 Test Loss: 1.38771 Test Accuracy: 0.55990\n",
            "epoch: 126 Train Loss: 1.43401 Train Acc: 0.53728 Test Loss: 1.37801 Test Accuracy: 0.55469\n",
            "epoch: 127 Train Loss: 1.42930 Train Acc: 0.54043 Test Loss: 1.36889 Test Accuracy: 0.56510\n",
            "epoch: 128 Train Loss: 1.43381 Train Acc: 0.53510 Test Loss: 1.37071 Test Accuracy: 0.55990\n",
            "epoch: 129 Train Loss: 1.44266 Train Acc: 0.52780 Test Loss: 1.37717 Test Accuracy: 0.56250\n",
            "epoch: 130 Train Loss: 1.43565 Train Acc: 0.52664 Test Loss: 1.37832 Test Accuracy: 0.55729\n",
            "epoch: 131 Train Loss: 1.42446 Train Acc: 0.55745 Test Loss: 1.37762 Test Accuracy: 0.55208\n",
            "epoch: 132 Train Loss: 1.43770 Train Acc: 0.54309 Test Loss: 1.37172 Test Accuracy: 0.55208\n",
            "epoch: 133 Train Loss: 1.41972 Train Acc: 0.54776 Test Loss: 1.36895 Test Accuracy: 0.56250\n",
            "epoch: 134 Train Loss: 1.42714 Train Acc: 0.53296 Test Loss: 1.37010 Test Accuracy: 0.55469\n",
            "epoch: 135 Train Loss: 1.39547 Train Acc: 0.54312 Test Loss: 1.36443 Test Accuracy: 0.56250\n",
            "epoch: 136 Train Loss: 1.41510 Train Acc: 0.53783 Test Loss: 1.37508 Test Accuracy: 0.55729\n",
            "epoch: 137 Train Loss: 1.40503 Train Acc: 0.54818 Test Loss: 1.36541 Test Accuracy: 0.56250\n",
            "epoch: 138 Train Loss: 1.40002 Train Acc: 0.55136 Test Loss: 1.36722 Test Accuracy: 0.56771\n",
            "epoch: 139 Train Loss: 1.40795 Train Acc: 0.53317 Test Loss: 1.36920 Test Accuracy: 0.55729\n",
            "epoch: 140 Train Loss: 1.38821 Train Acc: 0.56114 Test Loss: 1.36496 Test Accuracy: 0.56771\n",
            "epoch: 141 Train Loss: 1.40818 Train Acc: 0.55323 Test Loss: 1.35950 Test Accuracy: 0.57292\n",
            "epoch: 142 Train Loss: 1.40041 Train Acc: 0.53990 Test Loss: 1.36862 Test Accuracy: 0.55729\n",
            "epoch: 143 Train Loss: 1.39770 Train Acc: 0.55823 Test Loss: 1.36049 Test Accuracy: 0.56250\n",
            "epoch: 144 Train Loss: 1.38381 Train Acc: 0.54938 Test Loss: 1.35373 Test Accuracy: 0.57552\n",
            "epoch: 145 Train Loss: 1.38319 Train Acc: 0.55952 Test Loss: 1.35515 Test Accuracy: 0.56510\n",
            "epoch: 146 Train Loss: 1.37152 Train Acc: 0.55828 Test Loss: 1.37689 Test Accuracy: 0.53906\n",
            "epoch: 147 Train Loss: 1.38273 Train Acc: 0.56041 Test Loss: 1.34766 Test Accuracy: 0.55208\n",
            "epoch: 148 Train Loss: 1.38849 Train Acc: 0.56495 Test Loss: 1.37076 Test Accuracy: 0.55469\n",
            "epoch: 149 Train Loss: 1.37896 Train Acc: 0.56448 Test Loss: 1.35242 Test Accuracy: 0.54948\n",
            "epoch: 150 Train Loss: 1.37161 Train Acc: 0.57328 Test Loss: 1.34972 Test Accuracy: 0.56250\n",
            "epoch: 151 Train Loss: 1.37052 Train Acc: 0.56791 Test Loss: 1.35055 Test Accuracy: 0.55208\n",
            "epoch: 152 Train Loss: 1.35896 Train Acc: 0.56760 Test Loss: 1.34829 Test Accuracy: 0.55990\n",
            "epoch: 153 Train Loss: 1.36092 Train Acc: 0.55251 Test Loss: 1.34306 Test Accuracy: 0.55469\n",
            "epoch: 154 Train Loss: 1.34311 Train Acc: 0.58434 Test Loss: 1.36149 Test Accuracy: 0.52344\n",
            "epoch: 155 Train Loss: 1.36016 Train Acc: 0.56930 Test Loss: 1.34740 Test Accuracy: 0.55469\n",
            "epoch: 156 Train Loss: 1.36980 Train Acc: 0.56180 Test Loss: 1.35280 Test Accuracy: 0.55208\n",
            "epoch: 157 Train Loss: 1.36834 Train Acc: 0.56577 Test Loss: 1.35093 Test Accuracy: 0.54427\n",
            "epoch: 158 Train Loss: 1.35631 Train Acc: 0.55865 Test Loss: 1.34099 Test Accuracy: 0.56771\n",
            "epoch: 159 Train Loss: 1.34250 Train Acc: 0.57845 Test Loss: 1.34317 Test Accuracy: 0.54427\n",
            "epoch: 160 Train Loss: 1.34557 Train Acc: 0.57704 Test Loss: 1.33914 Test Accuracy: 0.55729\n",
            "epoch: 161 Train Loss: 1.34381 Train Acc: 0.57475 Test Loss: 1.34873 Test Accuracy: 0.54167\n",
            "epoch: 162 Train Loss: 1.34667 Train Acc: 0.56837 Test Loss: 1.35735 Test Accuracy: 0.54167\n",
            "epoch: 163 Train Loss: 1.35255 Train Acc: 0.58086 Test Loss: 1.34643 Test Accuracy: 0.54427\n",
            "epoch: 164 Train Loss: 1.32644 Train Acc: 0.59777 Test Loss: 1.34487 Test Accuracy: 0.55208\n",
            "epoch: 165 Train Loss: 1.32754 Train Acc: 0.58222 Test Loss: 1.33509 Test Accuracy: 0.55208\n",
            "epoch: 166 Train Loss: 1.32626 Train Acc: 0.56917 Test Loss: 1.33112 Test Accuracy: 0.54167\n",
            "epoch: 167 Train Loss: 1.31870 Train Acc: 0.58900 Test Loss: 1.33963 Test Accuracy: 0.52344\n",
            "epoch: 168 Train Loss: 1.32326 Train Acc: 0.56994 Test Loss: 1.34136 Test Accuracy: 0.55729\n",
            "epoch: 169 Train Loss: 1.32865 Train Acc: 0.57654 Test Loss: 1.34895 Test Accuracy: 0.54167\n",
            "epoch: 170 Train Loss: 1.32058 Train Acc: 0.57619 Test Loss: 1.33650 Test Accuracy: 0.56250\n",
            "epoch: 171 Train Loss: 1.31721 Train Acc: 0.58536 Test Loss: 1.34517 Test Accuracy: 0.53646\n",
            "epoch: 172 Train Loss: 1.31158 Train Acc: 0.59362 Test Loss: 1.35753 Test Accuracy: 0.52865\n",
            "epoch: 173 Train Loss: 1.30655 Train Acc: 0.58970 Test Loss: 1.33667 Test Accuracy: 0.54167\n",
            "epoch: 174 Train Loss: 1.30348 Train Acc: 0.58726 Test Loss: 1.34281 Test Accuracy: 0.54167\n",
            "epoch: 175 Train Loss: 1.30887 Train Acc: 0.58822 Test Loss: 1.33691 Test Accuracy: 0.57292\n",
            "epoch: 176 Train Loss: 1.29927 Train Acc: 0.58901 Test Loss: 1.33657 Test Accuracy: 0.51562\n",
            "epoch: 177 Train Loss: 1.30414 Train Acc: 0.58612 Test Loss: 1.33338 Test Accuracy: 0.55469\n",
            "epoch: 178 Train Loss: 1.30803 Train Acc: 0.59845 Test Loss: 1.34359 Test Accuracy: 0.53646\n",
            "epoch: 179 Train Loss: 1.28922 Train Acc: 0.58300 Test Loss: 1.33838 Test Accuracy: 0.51562\n",
            "epoch: 180 Train Loss: 1.29584 Train Acc: 0.59790 Test Loss: 1.33155 Test Accuracy: 0.56510\n",
            "epoch: 181 Train Loss: 1.29680 Train Acc: 0.57671 Test Loss: 1.32902 Test Accuracy: 0.55729\n",
            "epoch: 182 Train Loss: 1.28060 Train Acc: 0.60304 Test Loss: 1.36246 Test Accuracy: 0.49479\n",
            "epoch: 183 Train Loss: 1.28930 Train Acc: 0.59797 Test Loss: 1.33235 Test Accuracy: 0.55469\n",
            "epoch: 184 Train Loss: 1.28787 Train Acc: 0.61091 Test Loss: 1.33843 Test Accuracy: 0.56250\n",
            "epoch: 185 Train Loss: 1.27421 Train Acc: 0.61094 Test Loss: 1.34817 Test Accuracy: 0.54427\n",
            "epoch: 186 Train Loss: 1.28502 Train Acc: 0.59513 Test Loss: 1.34078 Test Accuracy: 0.53646\n",
            "epoch: 187 Train Loss: 1.26365 Train Acc: 0.60486 Test Loss: 1.33455 Test Accuracy: 0.55469\n",
            "epoch: 188 Train Loss: 1.27193 Train Acc: 0.60654 Test Loss: 1.32420 Test Accuracy: 0.54688\n",
            "epoch: 189 Train Loss: 1.29041 Train Acc: 0.58788 Test Loss: 1.34093 Test Accuracy: 0.54167\n",
            "epoch: 190 Train Loss: 1.28160 Train Acc: 0.59046 Test Loss: 1.32861 Test Accuracy: 0.54948\n",
            "epoch: 191 Train Loss: 1.26308 Train Acc: 0.61304 Test Loss: 1.35905 Test Accuracy: 0.54948\n",
            "epoch: 192 Train Loss: 1.27072 Train Acc: 0.60996 Test Loss: 1.33875 Test Accuracy: 0.55990\n",
            "epoch: 193 Train Loss: 1.26562 Train Acc: 0.61125 Test Loss: 1.34086 Test Accuracy: 0.52083\n",
            "epoch: 194 Train Loss: 1.26247 Train Acc: 0.60949 Test Loss: 1.34054 Test Accuracy: 0.51042\n",
            "epoch: 195 Train Loss: 1.25817 Train Acc: 0.61747 Test Loss: 1.34363 Test Accuracy: 0.54167\n",
            "epoch: 196 Train Loss: 1.25070 Train Acc: 0.61647 Test Loss: 1.33821 Test Accuracy: 0.55469\n",
            "epoch: 197 Train Loss: 1.26409 Train Acc: 0.61531 Test Loss: 1.31811 Test Accuracy: 0.51562\n",
            "epoch: 198 Train Loss: 1.24998 Train Acc: 0.61303 Test Loss: 1.33466 Test Accuracy: 0.54948\n",
            "epoch: 199 Train Loss: 1.24495 Train Acc: 0.61584 Test Loss: 1.32374 Test Accuracy: 0.54167\n",
            "epoch: 200 Train Loss: 1.25505 Train Acc: 0.61968 Test Loss: 1.34039 Test Accuracy: 0.50521\n",
            "epoch: 201 Train Loss: 1.23015 Train Acc: 0.62910 Test Loss: 1.33706 Test Accuracy: 0.49740\n",
            "epoch: 202 Train Loss: 1.24313 Train Acc: 0.62377 Test Loss: 1.33433 Test Accuracy: 0.51823\n",
            "epoch: 203 Train Loss: 1.24817 Train Acc: 0.61353 Test Loss: 1.32182 Test Accuracy: 0.53125\n",
            "epoch: 204 Train Loss: 1.24712 Train Acc: 0.61146 Test Loss: 1.34511 Test Accuracy: 0.53646\n",
            "epoch: 205 Train Loss: 1.24269 Train Acc: 0.61428 Test Loss: 1.34196 Test Accuracy: 0.52083\n",
            "epoch: 206 Train Loss: 1.21990 Train Acc: 0.63944 Test Loss: 1.33731 Test Accuracy: 0.49740\n",
            "epoch: 207 Train Loss: 1.23545 Train Acc: 0.64828 Test Loss: 1.32600 Test Accuracy: 0.51562\n",
            "epoch: 208 Train Loss: 1.23902 Train Acc: 0.64328 Test Loss: 1.33857 Test Accuracy: 0.54688\n",
            "epoch: 209 Train Loss: 1.22324 Train Acc: 0.64703 Test Loss: 1.31631 Test Accuracy: 0.53646\n",
            "epoch: 210 Train Loss: 1.22222 Train Acc: 0.63806 Test Loss: 1.34378 Test Accuracy: 0.53125\n",
            "epoch: 211 Train Loss: 1.21443 Train Acc: 0.63018 Test Loss: 1.34381 Test Accuracy: 0.51823\n",
            "epoch: 212 Train Loss: 1.21348 Train Acc: 0.61464 Test Loss: 1.33641 Test Accuracy: 0.54427\n",
            "epoch: 213 Train Loss: 1.21968 Train Acc: 0.64902 Test Loss: 1.32256 Test Accuracy: 0.53646\n",
            "epoch: 214 Train Loss: 1.20704 Train Acc: 0.63193 Test Loss: 1.34370 Test Accuracy: 0.52083\n",
            "epoch: 215 Train Loss: 1.20749 Train Acc: 0.62761 Test Loss: 1.32928 Test Accuracy: 0.53906\n",
            "epoch: 216 Train Loss: 1.20853 Train Acc: 0.64317 Test Loss: 1.33033 Test Accuracy: 0.54167\n",
            "epoch: 217 Train Loss: 1.21932 Train Acc: 0.65070 Test Loss: 1.33951 Test Accuracy: 0.49219\n",
            "epoch: 218 Train Loss: 1.20845 Train Acc: 0.64673 Test Loss: 1.34655 Test Accuracy: 0.52083\n",
            "epoch: 219 Train Loss: 1.21857 Train Acc: 0.64429 Test Loss: 1.33379 Test Accuracy: 0.49479\n",
            "epoch: 220 Train Loss: 1.20838 Train Acc: 0.63680 Test Loss: 1.33141 Test Accuracy: 0.50000\n",
            "epoch: 221 Train Loss: 1.19681 Train Acc: 0.64628 Test Loss: 1.32330 Test Accuracy: 0.53646\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-0733ce0e7e16>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m   \u001b[0;32mfor\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mInput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    626\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 628\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    629\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    630\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    669\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    670\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 671\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    672\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     56\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     56\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    229\u001b[0m         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 231\u001b[0;31m             \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtarget_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransforms\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m             \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1195\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torchvision/transforms/transforms.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, img)\u001b[0m\n\u001b[1;32m    961\u001b[0m         \"\"\"\n\u001b[1;32m    962\u001b[0m         \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_params\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mratio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 963\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresized_crop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mantialias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mantialias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    964\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mresized_crop\u001b[0;34m(img, top, left, height, width, size, interpolation, antialias)\u001b[0m\n\u001b[1;32m    631\u001b[0m         \u001b[0m_log_api_usage_once\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresized_crop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    632\u001b[0m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcrop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mleft\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 633\u001b[0;31m     \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mantialias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mantialias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    634\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    635\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation, max_size, antialias)\u001b[0m\n\u001b[1;32m    472\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Anti-alias option is always applied for PIL Image input. Argument antialias is ignored.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m         \u001b[0mpil_interpolation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpil_modes_mapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 474\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF_pil\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpil_interpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    475\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    476\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mF_t\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minterpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mantialias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mantialias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/torchvision/transforms/functional_pil.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(img, size, interpolation)\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Got inappropriate size arg: {size}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minterpolation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mresize\u001b[0;34m(self, size, resample, box, reducing_gap)\u001b[0m\n\u001b[1;32m   1903\u001b[0m                 )\n\u001b[1;32m   1904\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1905\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_new\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresample\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1906\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1907\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfactor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbox\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#### Trying Data Augumentation for tackling Overfitting didnt works quite well for this case/dataset ####\n",
        "#### following is the code for Augumentation ####\n",
        "\n",
        "\n",
        "# train_transforms_aug = transforms.Compose([\n",
        "#         transforms.Resize(size=(64,64)),\n",
        "#         transforms.TrivialAugumentWide(num_magnitude_bins=10),\n",
        "#         transforms.ToTensor(),\n",
        "#         transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "#     ])\n",
        "# test_transforms_sim = transforms.Compose([\n",
        "#         transforms.Resize(size=(64,64)),\n",
        "#         transforms.ToTensor(),\n",
        "#         transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "#     ])\n",
        "\n",
        "# train_data = datasets.ImageFolder(root='/content/classification_dataset/train',\n",
        "#                                   transform = train_transforms_aug,\n",
        "#                                   target_transform = None)\n",
        "# test_data = datasets.ImageFolder(root='/content/classification_dataset/test',\n",
        "#                                   transform = test_transforms_sim,\n",
        "#                                   target_transform = None)\n"
      ],
      "metadata": {
        "id": "otJB4M7GjGCR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##Following parts could also be used for getting Data##\n",
        "\n",
        "# import random\n",
        "\n",
        "# for dirpath, dirname, filenames in os.walk(\"/content/classification_dataset\"):\n",
        "#   print(f' there are {len(filenames)} image and {len(dirname)} directory In {dirpath}' )\n",
        "\n",
        "# train_path = \"/content/classification_dataset/train\"\n",
        "# test_path = \"/content/classification_dataset/test\"\n",
        "\n",
        "# image_path_list = glob.glob('/content/classification_dataset/*/*/*.jpg')\n",
        "\n",
        "# image_class = Path(random.choice(image_path_list)).parent.stem\n",
        "\n",
        "# Image.open(random_image_path)\n",
        "\n",
        "# class_names = train_data.class_to_idx\n",
        "\n",
        "#Following code can be used for Data visualization from datasets i.e, train_data created by torchvision datasets library\n",
        "\n",
        "# train_data[0]\n",
        "# img = train_data[1][0]\n",
        "# label = train_data[1][1]\n",
        "# img.shape, img.dtype\n",
        "# img_per = img.permute(1,2,0)\n",
        "# plt.figure(figsize = (20,14))\n",
        "# plt.imshow(img_per)\n",
        "# plt.show()"
      ],
      "metadata": {
        "id": "uZAVGkX_stK6"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}