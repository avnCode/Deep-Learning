{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard",
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 121,
      "metadata": {
        "id": "jjUxMT3I32u0"
      },
      "outputs": [],
      "source": [
        "import torch \n",
        "from torchvision import models\n",
        "from torch import nn\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res = models.resnet18(pretrained=True)\n",
        "# res.fc = nn.Linear(512,512)"
      ],
      "metadata": {
        "id": "KYtjZNyg4Roz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56d779c6-ead3-4abf-c9ce-9beb4f972cb7"
      },
      "execution_count": 122,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.8/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(res)\n",
        "res.to(\"cuda\")"
      ],
      "metadata": {
        "id": "e-VvfOo96PNl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(list(res.children()))\n",
        "res"
      ],
      "metadata": {
        "id": "OL_XkbI1WTWI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "  modules = list(res.children())[:-1]\n",
        "  res = torch.nn.Sequential(*modules)"
      ],
      "metadata": {
        "id": "SR1ZPHhZRCPl"
      },
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "koRkczac7dk9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "!unzip /content/drive/MyDrive/AIP/Train_Test_dataset.zip"
      ],
      "metadata": {
        "id": "rv8Rgibi6ZzC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocess_image(img_path):\n",
        "\n",
        "    preprocess = transforms.Compose([\n",
        "        transforms.Resize((224,224)), \n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
        "                              std=[0.229, 0.224, 0.225])])\n",
        "    \n",
        "    img = Image.open(img_path)\n",
        "    if img.mode != 'RGB':\n",
        "      img = img.convert('RGB')\n",
        "    img = preprocess(img).unsqueeze(0)\n",
        "    return img"
      ],
      "metadata": {
        "id": "5D5vMM3HCi62"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_output(img_path):\n",
        "  img = preprocess_image(img_path)\n",
        "  img = img.cuda()\n",
        "  features = res(img)[0,:,0,0]\n",
        "  return features"
      ],
      "metadata": {
        "id": "jZ-RSLy6FIZg"
      },
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import glob"
      ],
      "metadata": {
        "id": "T88z-1Wp8jw1"
      },
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Training Data set"
      ],
      "metadata": {
        "id": "Xg6nTFbwBA9w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bear = []\n",
        "butterfly = []\n",
        "camel = []\n",
        "chimp = []\n",
        "duck = []\n",
        "elephant = []\n",
        "\n",
        "res.eval()\n",
        "\n",
        "for img_path in glob.glob(\"/content/classification_dataset/train/bear/*.jpg\"):\n",
        "  arr_0 = np.append(get_output(img_path).cpu().detach().numpy(),0)\n",
        "  bear.append(arr_0)\n",
        "\n",
        "for img_path in glob.glob(\"/content/classification_dataset/train/butterfly/*.jpg\"):\n",
        "  arr_0 = np.append(get_output(img_path).cpu().detach().numpy(),1)\n",
        "  butterfly.append(arr_0)\n",
        "\n",
        "for img_path in glob.glob(\"/content/classification_dataset/train/camel/*.jpg\"):\n",
        "  arr_0 = np.append(get_output(img_path).cpu().detach().numpy(),2)\n",
        "  camel.append(arr_0)\n",
        "\n",
        "for img_path in glob.glob(\"/content/classification_dataset/train/chimp/*.jpg\"):\n",
        "  arr_0 = np.append(get_output(img_path).cpu().detach().numpy(),3)\n",
        "  chimp.append(arr_0)\n",
        "\n",
        "for img_path in glob.glob(\"/content/classification_dataset/train/duck/*.jpg\"):\n",
        "  arr_0 = np.append(get_output(img_path).cpu().detach().numpy(),4)\n",
        "  duck.append(arr_0)\n",
        "\n",
        "for img_path in glob.glob(\"/content/classification_dataset/train/elephant/*.jpg\"):\n",
        "  arr_0 = np.append(get_output(img_path).cpu().detach().numpy(),5)\n",
        "  elephant.append(arr_0)"
      ],
      "metadata": {
        "id": "txKnUekc_txh"
      },
      "execution_count": 135,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = np.vstack((bear,butterfly,camel,chimp,duck,elephant))\n",
        "np.save(\"Train_Data_Points\", X_train) \n",
        "len(X_train[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pw5ZTr_RA5zd",
        "outputId": "961358b5-9dc3-44e2-8f29-baa28b4fe0f6"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "513"
            ]
          },
          "metadata": {},
          "execution_count": 136
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Testing Data set"
      ],
      "metadata": {
        "id": "Pc1eHHo1A7ae"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bear = []\n",
        "butterfly = []\n",
        "camel = []\n",
        "chimp = []\n",
        "duck = []\n",
        "elephant = []\n",
        "\n",
        "res.eval()\n",
        "\n",
        "for img_path in glob.glob(\"/content/classification_dataset/test/bear/*.jpg\"):\n",
        "  arr_0 = np.append(get_output(img_path).cpu().detach().numpy(),0)\n",
        "  bear.append(arr_0)\n",
        "\n",
        "for img_path in glob.glob(\"/content/classification_dataset/test/butterfly/*.jpg\"):\n",
        "  arr_0 = np.append(get_output(img_path).cpu().detach().numpy(),1)\n",
        "  butterfly.append(arr_0)\n",
        "\n",
        "for img_path in glob.glob(\"/content/classification_dataset/test/camel/*.jpg\"):\n",
        "  arr_0 = np.append(get_output(img_path).cpu().detach().numpy(),2)\n",
        "  camel.append(arr_0)\n",
        "\n",
        "for img_path in glob.glob(\"/content/classification_dataset/test/chimp/*.jpg\"):\n",
        "  arr_0 = np.append(get_output(img_path).cpu().detach().numpy(),3)\n",
        "  chimp.append(arr_0)\n",
        "\n",
        "for img_path in glob.glob(\"/content/classification_dataset/test/duck/*.jpg\"):\n",
        "  arr_0 = np.append(get_output(img_path).cpu().detach().numpy(),4)\n",
        "  duck.append(arr_0)\n",
        "\n",
        "for img_path in glob.glob(\"/content/classification_dataset/test/elephant/*.jpg\"):\n",
        "  arr_0 = np.append(get_output(img_path).cpu().detach().numpy(),5)\n",
        "  elephant.append(arr_0)"
      ],
      "metadata": {
        "id": "LS1rS9lO_ftS"
      },
      "execution_count": 137,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = np.vstack((bear,butterfly,camel,chimp,duck,elephant))\n",
        "np.save(\"Test_Data_Points\", X_test) \n",
        "len(X_test[0])"
      ],
      "metadata": {
        "id": "pjBwBh4smJG4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0913fd00-165e-4afc-baff-303fd7590e12"
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "513"
            ]
          },
          "metadata": {},
          "execution_count": 138
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Loading data and performing KNN for accuracy checking\n"
      ],
      "metadata": {
        "id": "iXCYtcf_4fYz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix"
      ],
      "metadata": {
        "id": "lIptgNJXoaFt"
      },
      "execution_count": 139,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_train = np.load(\"Train_Data_Points.npy\")\n",
        "data_test = np.load(\"Test_Data_Points.npy\")\n",
        "\n",
        "np.random.shuffle(data_train)\n",
        "np.random.shuffle(data_test)"
      ],
      "metadata": {
        "id": "wW_0BaBc44TQ"
      },
      "execution_count": 140,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = data_train[:,:512]\n",
        "y_train = data_train[ : ,512]\n",
        "\n",
        "X_test = data_test[:,:512]\n",
        "y_test = data_test[ : ,512]"
      ],
      "metadata": {
        "id": "LgR3zIZW5D3N"
      },
      "execution_count": 141,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "knn = KNeighborsClassifier(n_neighbors=2)\n",
        "knn.fit(X_train, y_train)\n",
        "y_pred = knn.predict(X_test)"
      ],
      "metadata": {
        "id": "VuDjrpqg5cSx"
      },
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create the confusion matrix\n",
        "conf_matrix = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# calculate the accuracy\n",
        "accuracy = (conf_matrix[0,0] + conf_matrix[1,1] + conf_matrix[2,2] + conf_matrix[3,3] + conf_matrix[4,4] + conf_matrix[5,5]) / conf_matrix.sum()\n",
        "\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0S_n_kO5l-_",
        "outputId": "67c7e447-48f2-4a38-dc84-cbdab94a5062"
      },
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.95\n"
          ]
        }
      ]
    }
  ]
}